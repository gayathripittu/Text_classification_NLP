{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9603468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e178d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\Capstone\\Datasets\\Data_preparation\\preprocessed_labels3_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d5460e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "      <th>count_topics</th>\n",
       "      <th>text_expanded</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>remove_titles</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_wo_stopwords</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2289</td>\n",
       "      <td>CompuServe Corp. Tuesday reported a surprising...</td>\n",
       "      <td>['PERFORMANCE', 'ACCOUNTS/EARNINGS', 'CORPORAT...</td>\n",
       "      <td>3</td>\n",
       "      <td>CompuServe Corp. Tuesday reported a surprising...</td>\n",
       "      <td>compuserve corp tuesday reported a surprisingl...</td>\n",
       "      <td>compuserve corp tuesday reported a surprisingl...</td>\n",
       "      <td>['compuserve', 'corp', 'tuesday', 'reported', ...</td>\n",
       "      <td>['compuserve', 'corp', 'tuesday', 'reported', ...</td>\n",
       "      <td>['compuserve', 'corp', 'tuesday', 'report', 's...</td>\n",
       "      <td>compuserve corp tuesday report surprisingly la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2290</td>\n",
       "      <td>If dining at Planet Hollywood made you feel li...</td>\n",
       "      <td>['STRATEGY/PLANS', 'NEW_PRODUCTS/SERVICES', 'C...</td>\n",
       "      <td>3</td>\n",
       "      <td>If dining at Planet Hollywood made you feel li...</td>\n",
       "      <td>if dining at planet hollywood made you feel li...</td>\n",
       "      <td>if dining at planet hollywood made you feel li...</td>\n",
       "      <td>['if', 'dining', 'at', 'planet', 'hollywood', ...</td>\n",
       "      <td>['dining', 'planet', 'hollywood', 'made', 'fee...</td>\n",
       "      <td>['din', 'planet', 'hollywood', 'make', 'feel',...</td>\n",
       "      <td>din planet hollywood make feel like movie star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2302</td>\n",
       "      <td>Columbia/HCA Healthcare Corp.'s proposed $299....</td>\n",
       "      <td>['OWNERSHIP_CHANGES', 'MERGERS/ACQUISITIONS', ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Columbia/HCA Healthcare Corp.'s proposed $299....</td>\n",
       "      <td>columbiahca healthcare corps proposed  million...</td>\n",
       "      <td>columbiahca healthcare corps proposed  million...</td>\n",
       "      <td>['columbiahca', 'healthcare', 'corps', 'propos...</td>\n",
       "      <td>['columbiahca', 'healthcare', 'corps', 'propos...</td>\n",
       "      <td>['columbiahca', 'healthcare', 'corps', 'propos...</td>\n",
       "      <td>columbiahca healthcare corps propose million a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2307</td>\n",
       "      <td>World oil prices slipped on Tuesday in a marke...</td>\n",
       "      <td>['COMMODITY_MARKETS', 'ENERGY_MARKETS', 'MARKE...</td>\n",
       "      <td>3</td>\n",
       "      <td>World oil prices slipped on Tuesday in a marke...</td>\n",
       "      <td>world oil prices slipped on tuesday in a marke...</td>\n",
       "      <td>world oil prices slipped on tuesday in a marke...</td>\n",
       "      <td>['world', 'oil', 'prices', 'slipped', 'on', 't...</td>\n",
       "      <td>['world', 'oil', 'prices', 'slipped', 'tuesday...</td>\n",
       "      <td>['world', 'oil', 'price', 'slip', 'tuesday', '...</td>\n",
       "      <td>world oil price slip tuesday market refiners s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2312</td>\n",
       "      <td>Gulf War hero Colin Powell lent his prestige a...</td>\n",
       "      <td>['GOVERNMENT/SOCIAL', 'DOMESTIC_POLITICS', 'EL...</td>\n",
       "      <td>3</td>\n",
       "      <td>Gulf War hero Colin Powell lent his prestige a...</td>\n",
       "      <td>gulf war hero colin powell lent his prestige a...</td>\n",
       "      <td>gulf war hero colin powell lent his prestige a...</td>\n",
       "      <td>['gulf', 'war', 'hero', 'colin', 'powell', 'le...</td>\n",
       "      <td>['gulf', 'war', 'hero', 'colin', 'powell', 'le...</td>\n",
       "      <td>['gulf', 'war', 'hero', 'colin', 'powell', 'le...</td>\n",
       "      <td>gulf war hero colin powell lend prestige popul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid                                               text  \\\n",
       "0   2289  CompuServe Corp. Tuesday reported a surprising...   \n",
       "1   2290  If dining at Planet Hollywood made you feel li...   \n",
       "2   2302  Columbia/HCA Healthcare Corp.'s proposed $299....   \n",
       "3   2307  World oil prices slipped on Tuesday in a marke...   \n",
       "4   2312  Gulf War hero Colin Powell lent his prestige a...   \n",
       "\n",
       "                                              topics  count_topics  \\\n",
       "0  ['PERFORMANCE', 'ACCOUNTS/EARNINGS', 'CORPORAT...             3   \n",
       "1  ['STRATEGY/PLANS', 'NEW_PRODUCTS/SERVICES', 'C...             3   \n",
       "2  ['OWNERSHIP_CHANGES', 'MERGERS/ACQUISITIONS', ...             3   \n",
       "3  ['COMMODITY_MARKETS', 'ENERGY_MARKETS', 'MARKE...             3   \n",
       "4  ['GOVERNMENT/SOCIAL', 'DOMESTIC_POLITICS', 'EL...             3   \n",
       "\n",
       "                                       text_expanded  \\\n",
       "0  CompuServe Corp. Tuesday reported a surprising...   \n",
       "1  If dining at Planet Hollywood made you feel li...   \n",
       "2  Columbia/HCA Healthcare Corp.'s proposed $299....   \n",
       "3  World oil prices slipped on Tuesday in a marke...   \n",
       "4  Gulf War hero Colin Powell lent his prestige a...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  compuserve corp tuesday reported a surprisingl...   \n",
       "1  if dining at planet hollywood made you feel li...   \n",
       "2  columbiahca healthcare corps proposed  million...   \n",
       "3  world oil prices slipped on tuesday in a marke...   \n",
       "4  gulf war hero colin powell lent his prestige a...   \n",
       "\n",
       "                                       remove_titles  \\\n",
       "0  compuserve corp tuesday reported a surprisingl...   \n",
       "1  if dining at planet hollywood made you feel li...   \n",
       "2  columbiahca healthcare corps proposed  million...   \n",
       "3  world oil prices slipped on tuesday in a marke...   \n",
       "4  gulf war hero colin powell lent his prestige a...   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  ['compuserve', 'corp', 'tuesday', 'reported', ...   \n",
       "1  ['if', 'dining', 'at', 'planet', 'hollywood', ...   \n",
       "2  ['columbiahca', 'healthcare', 'corps', 'propos...   \n",
       "3  ['world', 'oil', 'prices', 'slipped', 'on', 't...   \n",
       "4  ['gulf', 'war', 'hero', 'colin', 'powell', 'le...   \n",
       "\n",
       "                                   text_wo_stopwords  \\\n",
       "0  ['compuserve', 'corp', 'tuesday', 'reported', ...   \n",
       "1  ['dining', 'planet', 'hollywood', 'made', 'fee...   \n",
       "2  ['columbiahca', 'healthcare', 'corps', 'propos...   \n",
       "3  ['world', 'oil', 'prices', 'slipped', 'tuesday...   \n",
       "4  ['gulf', 'war', 'hero', 'colin', 'powell', 'le...   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  ['compuserve', 'corp', 'tuesday', 'report', 's...   \n",
       "1  ['din', 'planet', 'hollywood', 'make', 'feel',...   \n",
       "2  ['columbiahca', 'healthcare', 'corps', 'propos...   \n",
       "3  ['world', 'oil', 'price', 'slip', 'tuesday', '...   \n",
       "4  ['gulf', 'war', 'hero', 'colin', 'powell', 'le...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  compuserve corp tuesday report surprisingly la...  \n",
       "1  din planet hollywood make feel like movie star...  \n",
       "2  columbiahca healthcare corps propose million a...  \n",
       "3  world oil price slip tuesday market refiners s...  \n",
       "4  gulf war hero colin powell lend prestige popul...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283e44f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics\n",
       "['PERFORMANCE', 'COMMENT/FORECASTS', 'CORPORATE/INDUSTRIAL']             53939\n",
       "['PERFORMANCE', 'ACCOUNTS/EARNINGS', 'CORPORATE/INDUSTRIAL']             50740\n",
       "['COMMODITY_MARKETS', 'SOFT_COMMODITIES', 'MARKETS']                     36090\n",
       "['OWNERSHIP_CHANGES', 'MERGERS/ACQUISITIONS', 'CORPORATE/INDUSTRIAL']    23106\n",
       "['MONEY_MARKETS', 'INTERBANK_MARKETS', 'MARKETS']                        20439\n",
       "['GOVERNMENT_FINANCE', 'GOVERNMENT_BORROWING', 'ECONOMICS']              17671\n",
       "['COMMODITY_MARKETS', 'ENERGY_MARKETS', 'MARKETS']                       17271\n",
       "['MONEY_MARKETS', 'FOREX_MARKETS', 'MARKETS']                            15811\n",
       "['FUNDING/CAPITAL', 'BONDS/DEBT_ISSUES', 'CORPORATE/INDUSTRIAL']          9489\n",
       "['COMMODITY_MARKETS', 'METALS_TRADING', 'MARKETS']                        7750\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topics'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01aa5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sampled data: (26000, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_52_topics = df['topics'].value_counts().head(52)\n",
    "\n",
    "# Create an empty DataFrame to store sampled data\n",
    "sampled_data = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for topic, count in top_52_topics.items():\n",
    "    # Filter rows for the current topic\n",
    "    topic_data = df[df['topics'] == topic]\n",
    "    \n",
    "    # If there are more than 500 samples, randomly select 500\n",
    "    if count > 500:\n",
    "        topic_data = topic_data.sample(n=500, random_state=42)\n",
    "    \n",
    "    # Append selected samples to the sampled_data DataFrame\n",
    "    sampled_data = pd.concat([sampled_data, topic_data])\n",
    "\n",
    "# Reset index of the sampled data\n",
    "sampled_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shape of the sampled data\n",
    "print(\"Shape of sampled data:\", sampled_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872c1c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26000, 71994)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorizer\n",
    "vect = CountVectorizer()  \n",
    "vects = vect.fit_transform(sampled_data.processed_text)\n",
    "vects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143a1932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71994, 26000)\n"
     ]
    }
   ],
   "source": [
    "tdm = vects.T\n",
    "\n",
    "term_document_matrix = pd.DataFrame.sparse.from_spmatrix(tdm, index=vect.get_feature_names_out(), columns=sampled_data['docid'].astype(str))\n",
    "\n",
    "print(term_document_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb45877",
   "metadata": {},
   "source": [
    "## Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972e3a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_values = term_document_matrix.max(axis=0)\n",
    "normalized_term_document_matrix =np.divide(term_document_matrix, max_values)\n",
    "normalized_term_document_matrix=normalized_term_document_matrix.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183aa703",
   "metadata": {},
   "source": [
    "## Truncate_SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df29811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of S:\n",
      "[[0.00720928 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.0157339  0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.0207617  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.07738285 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.07769975 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.07809511]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "k =150 \n",
    "svd = TruncatedSVD(n_components=k)\n",
    "\n",
    "U = svd.fit_transform(normalized_term_document_matrix)\n",
    "S = np.diag(svd.singular_values_)  \n",
    "VT = svd.components_\n",
    "\n",
    "\n",
    "S_inv = np.linalg.inv(S)\n",
    "\n",
    "print(\"Inverse of S:\")\n",
    "print(S_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5931a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xq_prime shape:  (26000, 71994)\n",
      "U shape:  (71994, 150)\n",
      "S_inv shape:  (150, 150)\n"
     ]
    }
   ],
   "source": [
    "Xq_prime = normalized_term_document_matrix.T\n",
    "\n",
    "print(\"Xq_prime shape: \",Xq_prime.shape)\n",
    "print(\"U shape: \",U.shape)\n",
    "print(\"S_inv shape: \",S_inv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f5a689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26000, 150)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dq = Xq_prime.dot(U).dot(S_inv)\n",
    "Dq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "386827a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26000, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data = sampled_data.reset_index(drop=True)\n",
    "sampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebbfb83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['PERFORMANCE', 'COMMENT/FORECASTS', 'CORPORATE/INDUSTRIAL']\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data['topics'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a601e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PERFORMANCE', 'COMMENT/FORECASTS', 'CORPORATE/INDUSTRIAL']\n"
     ]
    }
   ],
   "source": [
    "print(sampled_data['topics'][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7877b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>'</th>\n",
       "      <th>,</th>\n",
       "      <th>/</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>[</th>\n",
       "      <th>]</th>\n",
       "      <th>_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      '  ,  /  A  B  C  D  E  F  ...  S  T  U  V  W  X  Y  [  ]  _\n",
       "0  1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "1  1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "2  1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Instantiate the binarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform the 'topics' column of the DataFrame\n",
    "binary_labels = mlb.fit_transform(sampled_data['topics'])\n",
    "\n",
    "# Create a new DataFrame from the binary labels with appropriate column names\n",
    "mlb_df = pd.DataFrame(binary_labels, columns=mlb.classes_, index=sampled_data.index)\n",
    "mlb_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e22bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', \"'\", ',', '/', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I',\n",
       "       'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
       "       'X', 'Y', '[', ']', '_'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b00857f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26000, 150)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "531828e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26000, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9156ed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>'</th>\n",
       "      <th>,</th>\n",
       "      <th>/</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>[</th>\n",
       "      <th>]</th>\n",
       "      <th>_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          '  ,  /  A  B  C  D  E  F  ...  S  T  U  V  W  X  Y  [  ]  _\n",
       "0      1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "1      1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "2      1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "3      1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "4      1  1  1  1  1  0  1  1  1  1  ...  1  1  1  0  0  0  0  1  1  0\n",
       "...   .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. ..\n",
       "25995  1  1  1  1  1  0  1  0  1  0  ...  1  1  1  1  0  0  1  1  1  1\n",
       "25996  1  1  1  1  1  0  1  0  1  0  ...  1  1  1  1  0  0  1  1  1  1\n",
       "25997  1  1  1  1  1  0  1  0  1  0  ...  1  1  1  1  0  0  1  1  1  1\n",
       "25998  1  1  1  1  1  0  1  0  1  0  ...  1  1  1  1  0  0  1  1  1  1\n",
       "25999  1  1  1  1  1  0  1  0  1  0  ...  1  1  1  1  0  0  1  1  1  1\n",
       "\n",
       "[26000 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd5cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64b3cc5b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "922a26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 2.77%\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "                   1.00      1.00      1.00      5200\n",
      "           '       1.00      1.00      1.00      5200\n",
      "           ,       1.00      1.00      1.00      5200\n",
      "           /       0.99      1.00      0.99      4488\n",
      "           A       1.00      1.00      1.00      5200\n",
      "           B       0.85      0.89      0.87       528\n",
      "           C       1.00      1.00      1.00      4981\n",
      "           D       0.95      0.99      0.97      3977\n",
      "           E       1.00      1.00      1.00      5200\n",
      "           F       0.85      0.92      0.88      2576\n",
      "           G       0.93      0.99      0.96      3669\n",
      "           H       0.80      0.89      0.84       809\n",
      "           I       1.00      1.00      1.00      5090\n",
      "           K       0.82      0.92      0.87       897\n",
      "           L       0.97      0.99      0.98      4266\n",
      "           M       0.93      0.98      0.95      3747\n",
      "           N       1.00      1.00      1.00      5104\n",
      "           O       1.00      1.00      1.00      5200\n",
      "           P       0.94      0.98      0.96      3678\n",
      "           Q       0.53      0.58      0.55        86\n",
      "           R       1.00      1.00      1.00      5200\n",
      "           S       1.00      1.00      1.00      5200\n",
      "           T       1.00      1.00      1.00      5200\n",
      "           U       0.94      0.98      0.96      2972\n",
      "           V       0.87      0.95      0.91      2579\n",
      "           W       0.79      0.90      0.84      1275\n",
      "           X       0.79      0.86      0.82       307\n",
      "           Y       0.87      0.95      0.91      1918\n",
      "           [       1.00      1.00      1.00      5200\n",
      "           ]       1.00      1.00      1.00      5200\n",
      "           _       0.94      0.97      0.95      3804\n",
      "\n",
      "   micro avg       0.97      0.99      0.98    113951\n",
      "   macro avg       0.93      0.96      0.94    113951\n",
      "weighted avg       0.97      0.99      0.98    113951\n",
      " samples avg       0.97      0.99      0.98    113951\n",
      "\n",
      "Test Set Macro-average F1 score: 0.94\n",
      "Test Set Micro-average F1 score: 0.98\n",
      "Test Set Weighted-average F1 score: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split data into train+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(Dq, mlb_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train+validation into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train model using the training set and validate it using the validation set\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {test_accuracy*100:.2f}%')\n",
    "\n",
    "# Generate predictions\n",
    "predicted_probs_test = model.predict(X_test)\n",
    "predicted_labels_test = (predicted_probs_test > 0.3).astype(int)\n",
    "\n",
    "# Generate classification report for the test set\n",
    "test_report = classification_report(y_test, predicted_labels_test, target_names=mlb.classes_, output_dict=True)\n",
    "print(\"\\nTest Set Classification Report:\\n\", classification_report(y_test, predicted_labels_test, target_names=mlb.classes_))\n",
    "\n",
    "# Print F1 scores for the test set\n",
    "print(f\"Test Set Macro-average F1 score: {test_report['macro avg']['f1-score']:.2f}\")\n",
    "print(f\"Test Set Micro-average F1 score: {test_report['micro avg']['f1-score']:.2f}\")\n",
    "print(f\"Test Set Weighted-average F1 score: {test_report['weighted avg']['f1-score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5683654d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 2ms/step\n",
      "82/82 [==============================] - 0s 1ms/step\n",
      "82/82 [==============================] - 0s 2ms/step\n",
      "82/82 [==============================] - 0s 2ms/step\n",
      "82/82 [==============================] - 0s 2ms/step\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "                   1.00      1.00      1.00     26000\n",
      "           '       1.00      1.00      1.00     26000\n",
      "           ,       1.00      1.00      1.00     26000\n",
      "           /       0.97      0.99      0.98     22500\n",
      "           A       1.00      1.00      1.00     26000\n",
      "           B       0.93      0.52      0.66      2500\n",
      "           C       0.99      1.00      0.99     25000\n",
      "           D       0.90      0.97      0.93     20000\n",
      "           E       1.00      1.00      1.00     26000\n",
      "           F       0.78      0.75      0.77     12500\n",
      "           G       0.90      0.96      0.93     18500\n",
      "           H       0.83      0.36      0.50      4000\n",
      "           I       1.00      1.00      1.00     25500\n",
      "           K       0.86      0.66      0.75      4500\n",
      "           L       0.94      0.98      0.96     21500\n",
      "           M       0.92      0.94      0.93     19000\n",
      "           N       0.98      1.00      0.99     25500\n",
      "           O       1.00      1.00      1.00     26000\n",
      "           P       0.93      0.92      0.93     18500\n",
      "           Q       0.00      0.00      0.00       500\n",
      "           R       1.00      1.00      1.00     26000\n",
      "           S       1.00      1.00      1.00     26000\n",
      "           T       1.00      1.00      1.00     26000\n",
      "           U       0.88      0.92      0.90     15000\n",
      "           V       0.88      0.81      0.84     13000\n",
      "           W       0.78      0.61      0.68      6500\n",
      "           X       0.93      0.41      0.57      1500\n",
      "           Y       0.83      0.66      0.74      9500\n",
      "           [       1.00      1.00      1.00     26000\n",
      "           ]       1.00      1.00      1.00     26000\n",
      "           _       0.90      0.92      0.91     19000\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    570500\n",
      "   macro avg       0.91      0.85      0.87    570500\n",
      "weighted avg       0.96      0.96      0.96    570500\n",
      " samples avg       0.96      0.96      0.96    570500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gayat\\.conda\\envs\\pracenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming Dq is your features and mlb_df is your encoded labels\n",
    "X = Dq\n",
    "y = mlb_df.values\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Placeholder for aggregated test set results\n",
    "y_test_all = []\n",
    "predicted_labels_all = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y.argmax(1)):  # Using argmax to simulate stratification\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='sigmoid')  # Sigmoid activation for multilabel classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define early stopping criteria\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=64, \n",
    "              validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Generate predictions for this fold's test set\n",
    "    predicted_probs = model.predict(X_test)\n",
    "    predicted_labels = (predicted_probs > 0.5).astype(int)\n",
    "    \n",
    "    # Aggregate the results\n",
    "    y_test_all.append(y_test)\n",
    "    predicted_labels_all.append(predicted_labels)\n",
    "\n",
    "# Concatenate all test set results\n",
    "y_test_all = np.concatenate(y_test_all, axis=0)\n",
    "predicted_labels_all = np.concatenate(predicted_labels_all, axis=0)\n",
    "\n",
    "# Generate and print the overall classification report\n",
    "report = classification_report(y_test_all, predicted_labels_all, target_names=mlb.classes_)\n",
    "print(\"Overall Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b417873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3684d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fa1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5326dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
