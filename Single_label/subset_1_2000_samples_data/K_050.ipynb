{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39124ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6fdb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\Capstone\\Datasets\\Data_preparation\\preprocessed\\Preprocessed_2000_samples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a07c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['text_lemmatized'] = df['text_lemmatized'].apply(ast.literal_eval)\n",
    "\n",
    "# Now you can proceed with concatenating the lists into sentences\n",
    "df['sentences'] = df['text_lemmatized'].apply(lambda x: ' '.join(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31629b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20782)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorizer\n",
    "vect = CountVectorizer()  \n",
    "vects = vect.fit_transform(df.sentences)\n",
    "vects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2c3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20782, 2000)\n"
     ]
    }
   ],
   "source": [
    "tdm = vects.T\n",
    "\n",
    "term_document_matrix = pd.DataFrame.sparse.from_spmatrix(tdm, index=vect.get_feature_names_out(), columns=df['docid'].astype(str))\n",
    "\n",
    "print(term_document_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459ca12",
   "metadata": {},
   "source": [
    "## Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece229e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_values = term_document_matrix.max(axis=0)\n",
    "normalized_term_document_matrix =np.divide(term_document_matrix, max_values)\n",
    "normalized_term_document_matrix=normalized_term_document_matrix.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16064a2",
   "metadata": {},
   "source": [
    "## TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df98c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of S:\n",
      "[[0.02287395 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.05431071 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.05737427 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.16156731 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.16313911 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.16473821]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "k = 50 \n",
    "svd = TruncatedSVD(n_components=k)\n",
    "\n",
    "U = svd.fit_transform(normalized_term_document_matrix)\n",
    "S = np.diag(svd.singular_values_)  \n",
    "VT = svd.components_\n",
    "\n",
    "\n",
    "S_inv = np.linalg.inv(S)\n",
    "\n",
    "print(\"Inverse of S:\")\n",
    "print(S_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e4a682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xq_prime shape:  (2000, 20782)\n",
      "U shape:  (20782, 50)\n",
      "S_inv shape:  (50, 50)\n"
     ]
    }
   ],
   "source": [
    "Xq_prime = normalized_term_document_matrix.T\n",
    "\n",
    "print(\"Xq_prime shape: \",Xq_prime.shape)\n",
    "print(\"U shape: \",U.shape)\n",
    "print(\"S_inv shape: \",S_inv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491dd3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dq = Xq_prime.dot(U).dot(S_inv)\n",
    "Dq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb4555e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=list(df['encoded_topics'].unique())\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd78dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping = {old_label: new_label for new_label, old_label in enumerate(df['encoded_topics'].unique())}\n",
    "df['encoded_topics'] = df['encoded_topics'].map(class_mapping)\n",
    "df['encoded_topics'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "952fdb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Class Categories:\n",
      "Encoded Label 0: Original Label 69\n",
      "Encoded Label 1: Original Label 4\n",
      "Encoded Label 2: Original Label 41\n",
      "Encoded Label 3: Original Label 20\n",
      "Encoded Label 4: Original Label 55\n",
      "Encoded Label 5: Original Label 0\n",
      "Encoded Label 6: Original Label 27\n",
      "Encoded Label 7: Original Label 6\n",
      "Encoded Label 8: Original Label 13\n",
      "Encoded Label 9: Original Label 52\n"
     ]
    }
   ],
   "source": [
    "reverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "print(\"Old Class Categories:\")\n",
    "for encoded_label, old_label in reverse_class_mapping.items():\n",
    "    print(f\"Encoded Label {encoded_label}: Original Label {old_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf1676",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e38b36",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5fc0ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8711 - accuracy: 0.7100\n",
      "Test accuracy for fold 1: 71.00%\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Fold 2/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8286 - accuracy: 0.7350\n",
      "Test accuracy for fold 2: 73.50%\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Fold 3/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9504 - accuracy: 0.7250\n",
      "Test accuracy for fold 3: 72.50%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 4/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8319 - accuracy: 0.7450\n",
      "Test accuracy for fold 4: 74.50%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 5/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7985 - accuracy: 0.7450\n",
      "Test accuracy for fold 5: 74.50%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 6/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7862 - accuracy: 0.7500\n",
      "Test accuracy for fold 6: 75.00%\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Fold 7/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7115 - accuracy: 0.7350\n",
      "Test accuracy for fold 7: 73.50%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 8/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.7800\n",
      "Test accuracy for fold 8: 78.00%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 9/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9067 - accuracy: 0.6900\n",
      "Test accuracy for fold 9: 69.00%\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Fold 10/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7508 - accuracy: 0.7400\n",
      "Test accuracy for fold 10: 74.00%\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Classification Report with Average Test Accuracy:\n",
      " Average Test Accuracy: 73.55%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       200\n",
      "           1       0.80      0.66      0.72       200\n",
      "           2       0.84      0.80      0.82       200\n",
      "           3       0.73      0.70      0.72       200\n",
      "           4       0.64      0.65      0.64       200\n",
      "           5       0.53      0.58      0.55       200\n",
      "           6       0.78      0.74      0.76       200\n",
      "           7       0.66      0.68      0.67       200\n",
      "           8       0.65      0.74      0.69       200\n",
      "           9       0.91      0.87      0.89       200\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.74      0.74      0.74      2000\n",
      "weighted avg       0.74      0.74      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize variables to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "num_folds=10\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)# Initialize list to store test accuracies\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(Dq, df['encoded_topics'])):\n",
    "    print(f'Fold {fold + 1}/{num_folds}')\n",
    "\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = Dq[train_index], Dq[test_index]\n",
    "    y_train, y_test = df['encoded_topics'].iloc[train_index], df['encoded_topics'].iloc[test_index]\n",
    "\n",
    "    num_classes = len(np.unique(np.concatenate((y_train, y_test))))\n",
    "\n",
    "    y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train_flattened.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define early stopping criteria\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train_flattened, y_train_encoded, epochs=100, batch_size=64, \n",
    "                        validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model on the test set and collect predictions\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_flattened, y_test_encoded)\n",
    "    print(f'Test accuracy for fold {fold + 1}: {test_accuracy*100:.2f}%')\n",
    "\n",
    "    # Store test accuracy for this fold\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Collect true labels and predicted labels\n",
    "    true_labels.extend(y_test)\n",
    "    predicted_probs = model.predict(X_test_flattened)\n",
    "    predicted_labels.extend(np.argmax(predicted_probs, axis=1))\n",
    "\n",
    "# Calculate average test accuracy\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Add average accuracy to the report\n",
    "report_with_avg_accuracy = f'Average Test Accuracy: {avg_test_accuracy*100:.2f}%\\n\\n{report}'\n",
    "print(\"Classification Report with Average Test Accuracy:\\n\", report_with_avg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cabecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8419 - accuracy: 0.7150\n",
      "Test accuracy for fold 1: 71.50%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 2/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8320 - accuracy: 0.7250\n",
      "Test accuracy for fold 2: 72.50%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 3/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9218 - accuracy: 0.7250\n",
      "Test accuracy for fold 3: 72.50%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 4/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8238 - accuracy: 0.7200\n",
      "Test accuracy for fold 4: 72.00%\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fold 5/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8058 - accuracy: 0.7400\n",
      "Test accuracy for fold 5: 74.00%\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Fold 6/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7801 - accuracy: 0.7300\n",
      "Test accuracy for fold 6: 73.00%\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "Fold 7/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7346 - accuracy: 0.7350\n",
      "Test accuracy for fold 7: 73.50%\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Fold 8/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.7750\n",
      "Test accuracy for fold 8: 77.50%\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "Fold 9/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9367 - accuracy: 0.7100\n",
      "Test accuracy for fold 9: 71.00%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Fold 10/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7729 - accuracy: 0.7300\n",
      "Test accuracy for fold 10: 73.00%\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Classification Report with Average Test Accuracy:\n",
      " Average Test Accuracy: 73.05%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       200\n",
      "           1       0.76      0.67      0.71       200\n",
      "           2       0.85      0.80      0.82       200\n",
      "           3       0.72      0.72      0.72       200\n",
      "           4       0.65      0.65      0.65       200\n",
      "           5       0.51      0.56      0.54       200\n",
      "           6       0.78      0.74      0.76       200\n",
      "           7       0.65      0.65      0.65       200\n",
      "           8       0.64      0.72      0.68       200\n",
      "           9       0.91      0.88      0.89       200\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.74      0.73      0.73      2000\n",
      "weighted avg       0.74      0.73      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize variables to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Initialize list to store test accuracies\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(Dq, df['encoded_topics'])):\n",
    "    print(f'Fold {fold + 1}/{num_folds}')\n",
    "\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = Dq[train_index], Dq[test_index]\n",
    "    y_train, y_test = df['encoded_topics'].iloc[train_index], df['encoded_topics'].iloc[test_index]\n",
    "\n",
    "    num_classes = len(np.unique(np.concatenate((y_train, y_test))))\n",
    "\n",
    "    y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train_flattened.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define early stopping criteria\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train_flattened, y_train_encoded, epochs=100, batch_size=64, \n",
    "                        validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model on the test set and collect predictions\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_flattened, y_test_encoded)\n",
    "    print(f'Test accuracy for fold {fold + 1}: {test_accuracy*100:.2f}%')\n",
    "\n",
    "    # Store test accuracy for this fold\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Collect true labels and predicted labels\n",
    "    true_labels.extend(y_test)\n",
    "    predicted_probs = model.predict(X_test_flattened)\n",
    "    predicted_labels.extend(np.argmax(predicted_probs, axis=1))\n",
    "\n",
    "# Calculate average test accuracy\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Add average accuracy to the report\n",
    "report_with_avg_accuracy = f'Average Test Accuracy: {avg_test_accuracy*100:.2f}%\\n\\n{report}'\n",
    "print(\"Classification Report with Average Test Accuracy:\\n\", report_with_avg_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41d716",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92579936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 40ms/step - loss: 2.1895 - accuracy: 0.2648 - val_loss: 2.0112 - val_accuracy: 0.5188\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.8028 - accuracy: 0.5352 - val_loss: 1.5322 - val_accuracy: 0.5938\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3453 - accuracy: 0.6344 - val_loss: 1.1153 - val_accuracy: 0.6938\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 1.0708 - accuracy: 0.6727 - val_loss: 0.9630 - val_accuracy: 0.6906\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.9124 - accuracy: 0.7031 - val_loss: 0.8799 - val_accuracy: 0.6938\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.8506 - accuracy: 0.7211 - val_loss: 0.8629 - val_accuracy: 0.7063\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.7894 - accuracy: 0.7422 - val_loss: 0.8265 - val_accuracy: 0.7219\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.7683 - accuracy: 0.7500 - val_loss: 0.8090 - val_accuracy: 0.7156\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.7243 - accuracy: 0.7609 - val_loss: 0.8226 - val_accuracy: 0.7125\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.7053 - accuracy: 0.7648 - val_loss: 0.8081 - val_accuracy: 0.7094\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6852 - accuracy: 0.7711 - val_loss: 0.8122 - val_accuracy: 0.6938\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6688 - accuracy: 0.7867 - val_loss: 0.8116 - val_accuracy: 0.7094\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6154 - accuracy: 0.7937 - val_loss: 0.8154 - val_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6219 - accuracy: 0.7937 - val_loss: 0.8047 - val_accuracy: 0.7031\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6032 - accuracy: 0.7906 - val_loss: 0.8239 - val_accuracy: 0.7063\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6197 - accuracy: 0.7789 - val_loss: 0.8039 - val_accuracy: 0.7156\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5989 - accuracy: 0.8008 - val_loss: 0.8359 - val_accuracy: 0.7094\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5405 - accuracy: 0.8133 - val_loss: 0.8091 - val_accuracy: 0.7031\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5533 - accuracy: 0.8016 - val_loss: 0.8122 - val_accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5367 - accuracy: 0.8133 - val_loss: 0.8130 - val_accuracy: 0.7094\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5288 - accuracy: 0.8141 - val_loss: 0.8176 - val_accuracy: 0.7031\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8584 - accuracy: 0.7425\n",
      "Test accuracy: 74.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# Then proceed with train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Dq, \n",
    "    df['encoded_topics'], \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['encoded_topics']  # This ensures stratified splitting\n",
    ")\n",
    "\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train_flattened.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train_flattened, y_train_encoded, epochs=100, batch_size=64, \n",
    "                    validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_flattened, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a9c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.84      0.95      0.89        40\n",
      "     Class 2       0.82      0.68      0.74        40\n",
      "     Class 3       0.94      0.80      0.86        40\n",
      "     Class 4       0.78      0.72      0.75        40\n",
      "     Class 5       0.65      0.65      0.65        40\n",
      "     Class 6       0.46      0.47      0.47        40\n",
      "     Class 7       0.69      0.78      0.73        40\n",
      "     Class 8       0.70      0.65      0.68        40\n",
      "     Class 9       0.69      0.78      0.73        40\n",
      "    Class 10       0.88      0.95      0.92        40\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.75      0.74      0.74       400\n",
      "weighted avg       0.75      0.74      0.74       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from numpy import argmax, unique\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test_flattened)  # Ensure this matches your reshaped test data variable\n",
    "\n",
    "\n",
    "predictions_int = argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "y_test_int = argmax(y_test_encoded, axis=1)\n",
    "\n",
    "\n",
    "all_classes = unique(np.concatenate((y_test_int, predictions_int)))\n",
    "\n",
    "\n",
    "target_names = [f'Class {i+1}' for i in all_classes]  \n",
    "\n",
    "\n",
    "report = classification_report(y_test_int, predictions_int, target_names=target_names)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53341b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
