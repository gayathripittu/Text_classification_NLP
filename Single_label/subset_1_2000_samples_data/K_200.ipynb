{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39124ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6fdb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\Capstone\\Datasets\\Data_preparation\\preprocessed\\Preprocessed_2000_samples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a07c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['text_lemmatized'] = df['text_lemmatized'].apply(ast.literal_eval)\n",
    "\n",
    "# Now you can proceed with concatenating the lists into sentences\n",
    "df['sentences'] = df['text_lemmatized'].apply(lambda x: ' '.join(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31629b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20782)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorizer\n",
    "vect = CountVectorizer()  \n",
    "vects = vect.fit_transform(df.sentences)\n",
    "vects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2c3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20782, 2000)\n"
     ]
    }
   ],
   "source": [
    "tdm = vects.T\n",
    "\n",
    "term_document_matrix = pd.DataFrame.sparse.from_spmatrix(tdm, index=vect.get_feature_names_out(), columns=df['docid'].astype(str))\n",
    "\n",
    "print(term_document_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459ca12",
   "metadata": {},
   "source": [
    "## Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece229e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_values = term_document_matrix.max(axis=0)\n",
    "normalized_term_document_matrix =np.divide(term_document_matrix, max_values)\n",
    "normalized_term_document_matrix=normalized_term_document_matrix.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16064a2",
   "metadata": {},
   "source": [
    "## TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df98c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of S:\n",
      "[[0.02287395 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.05431071 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.05737427 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.2704472  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.27097399 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.2726388 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "k = 200 \n",
    "svd = TruncatedSVD(n_components=k)\n",
    "\n",
    "U = svd.fit_transform(normalized_term_document_matrix)\n",
    "S = np.diag(svd.singular_values_)  \n",
    "VT = svd.components_\n",
    "\n",
    "\n",
    "S_inv = np.linalg.inv(S)\n",
    "\n",
    "print(\"Inverse of S:\")\n",
    "print(S_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e4a682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xq_prime shape:  (2000, 20782)\n",
      "U shape:  (20782, 200)\n",
      "S_inv shape:  (200, 200)\n"
     ]
    }
   ],
   "source": [
    "Xq_prime = normalized_term_document_matrix.T\n",
    "\n",
    "print(\"Xq_prime shape: \",Xq_prime.shape)\n",
    "print(\"U shape: \",U.shape)\n",
    "print(\"S_inv shape: \",S_inv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491dd3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dq = Xq_prime.dot(U).dot(S_inv)\n",
    "Dq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb4555e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=list(df['encoded_topics'].unique())\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd78dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping = {old_label: new_label for new_label, old_label in enumerate(df['encoded_topics'].unique())}\n",
    "df['encoded_topics'] = df['encoded_topics'].map(class_mapping)\n",
    "df['encoded_topics'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "952fdb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Class Categories:\n",
      "Encoded Label 0: Original Label 69\n",
      "Encoded Label 1: Original Label 4\n",
      "Encoded Label 2: Original Label 41\n",
      "Encoded Label 3: Original Label 20\n",
      "Encoded Label 4: Original Label 55\n",
      "Encoded Label 5: Original Label 0\n",
      "Encoded Label 6: Original Label 27\n",
      "Encoded Label 7: Original Label 6\n",
      "Encoded Label 8: Original Label 13\n",
      "Encoded Label 9: Original Label 52\n"
     ]
    }
   ],
   "source": [
    "reverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "print(\"Old Class Categories:\")\n",
    "for encoded_label, old_label in reverse_class_mapping.items():\n",
    "    print(f\"Encoded Label {encoded_label}: Original Label {old_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf1676",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e38b36",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5fc0ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7407 - accuracy: 0.7700\n",
      "Test accuracy for fold 1: 77.00%\n",
      "Fold 2/10\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7603 - accuracy: 0.7700\n",
      "Test accuracy for fold 2: 77.00%\n",
      "Fold 3/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7679 - accuracy: 0.7700\n",
      "Test accuracy for fold 3: 77.00%\n",
      "Fold 4/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8578 - accuracy: 0.7450\n",
      "Test accuracy for fold 4: 74.50%\n",
      "Fold 5/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.8000\n",
      "Test accuracy for fold 5: 80.00%\n",
      "Fold 6/10\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.7103 - accuracy: 0.7750\n",
      "Test accuracy for fold 6: 77.50%\n",
      "Fold 7/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6630 - accuracy: 0.8000\n",
      "Test accuracy for fold 7: 80.00%\n",
      "Fold 8/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.8250\n",
      "Test accuracy for fold 8: 82.50%\n",
      "Fold 9/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8570 - accuracy: 0.7100\n",
      "Test accuracy for fold 9: 71.00%\n",
      "Fold 10/10\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6661 - accuracy: 0.8150\n",
      "Test accuracy for fold 10: 81.50%\n",
      "Average test accuracy: 77.80%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Initialize cross-validation\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize variables to store test accuracies\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(Dq, df['encoded_topics'])):\n",
    "    print(f'Fold {fold + 1}/{num_folds}')\n",
    "\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = Dq[train_index], Dq[test_index]\n",
    "    y_train, y_test = df['encoded_topics'].iloc[train_index], df['encoded_topics'].iloc[test_index]\n",
    "\n",
    "    num_classes = len(np.unique(np.concatenate((y_train, y_test))))\n",
    "\n",
    "    y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train_flattened.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define early stopping criteria\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train_flattened, y_train_encoded, epochs=100, batch_size=64, \n",
    "                        validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_flattened, y_test_encoded)\n",
    "    print(f'Test accuracy for fold {fold + 1}: {test_accuracy*100:.2f}%')\n",
    "\n",
    "    # Store the test accuracy for this fold\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Calculate and print the average test accuracy across all folds\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "print(f'Average test accuracy: {avg_test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab7198c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.83      1.00      0.91        20\n",
      "     Class 2       0.85      0.85      0.85        20\n",
      "     Class 3       0.88      0.70      0.78        20\n",
      "     Class 4       0.86      0.95      0.90        20\n",
      "     Class 5       0.68      0.65      0.67        20\n",
      "     Class 6       0.74      0.70      0.72        20\n",
      "     Class 7       0.88      0.75      0.81        20\n",
      "     Class 8       0.71      0.75      0.73        20\n",
      "     Class 9       0.75      0.90      0.82        20\n",
      "    Class 10       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.82      0.81       200\n",
      "weighted avg       0.82      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from numpy import argmax, unique\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test_flattened)  # Ensure this matches your reshaped test data variable\n",
    "\n",
    "\n",
    "predictions_int = argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "y_test_int = argmax(y_test_encoded, axis=1)\n",
    "\n",
    "\n",
    "all_classes = unique(np.concatenate((y_test_int, predictions_int)))\n",
    "\n",
    "\n",
    "target_names = [f'Class {i+1}' for i in all_classes]  \n",
    "\n",
    "\n",
    "report = classification_report(y_test_int, predictions_int, target_names=target_names)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cabecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7884 - accuracy: 0.7350\n",
      "Test accuracy for fold 1: 73.50%\n",
      "Fold 2/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7392 - accuracy: 0.7750\n",
      "Test accuracy for fold 2: 77.50%\n",
      "Fold 3/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.7600\n",
      "Test accuracy for fold 3: 76.00%\n",
      "Fold 4/10\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.8571 - accuracy: 0.7100\n",
      "Test accuracy for fold 4: 71.00%\n",
      "Fold 5/10\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6709 - accuracy: 0.7850\n",
      "Test accuracy for fold 5: 78.50%\n",
      "Fold 6/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.7500\n",
      "Test accuracy for fold 6: 75.00%\n",
      "Fold 7/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.7950\n",
      "Test accuracy for fold 7: 79.50%\n",
      "Fold 8/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.8200\n",
      "Test accuracy for fold 8: 82.00%\n",
      "Fold 9/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8100 - accuracy: 0.7400\n",
      "Test accuracy for fold 9: 74.00%\n",
      "Fold 10/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.8050\n",
      "Test accuracy for fold 10: 80.50%\n",
      "Average test accuracy: 76.75%\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "\n",
    "# Initialize cross-validation\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize variables to store test accuracies\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(Dq, df['encoded_topics'])):\n",
    "    print(f'Fold {fold + 1}/{num_folds}')\n",
    "\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = Dq[train_index], Dq[test_index]\n",
    "    y_train, y_test = df['encoded_topics'].iloc[train_index], df['encoded_topics'].iloc[test_index]\n",
    "\n",
    "    num_classes = len(np.unique(np.concatenate((y_train, y_test))))\n",
    "\n",
    "    y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train_flattened.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define early stopping criteria\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train_flattened, y_train_encoded, epochs=100, batch_size=64, \n",
    "                        validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_flattened, y_test_encoded)\n",
    "    print(f'Test accuracy for fold {fold + 1}: {test_accuracy*100:.2f}%')\n",
    "\n",
    "    # Store the test accuracy for this fold\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Calculate and print the average test accuracy across all folds\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "print(f'Average test accuracy: {avg_test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc52ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.87      1.00      0.93        20\n",
      "     Class 2       0.88      0.75      0.81        20\n",
      "     Class 3       0.92      0.60      0.73        20\n",
      "     Class 4       0.81      0.85      0.83        20\n",
      "     Class 5       0.70      0.80      0.74        20\n",
      "     Class 6       0.65      0.65      0.65        20\n",
      "     Class 7       0.88      0.75      0.81        20\n",
      "     Class 8       0.76      0.80      0.78        20\n",
      "     Class 9       0.70      0.95      0.81        20\n",
      "    Class 10       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.81      0.80       200\n",
      "weighted avg       0.82      0.81      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from numpy import argmax, unique\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test_flattened)  # Ensure this matches your reshaped test data variable\n",
    "\n",
    "\n",
    "predictions_int = argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "y_test_int = argmax(y_test_encoded, axis=1)\n",
    "\n",
    "\n",
    "all_classes = unique(np.concatenate((y_test_int, predictions_int)))\n",
    "\n",
    "\n",
    "target_names = [f'Class {i+1}' for i in all_classes]  \n",
    "\n",
    "\n",
    "report = classification_report(y_test_int, predictions_int, target_names=target_names)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d09e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92579936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 17ms/step - loss: 2.2234 - accuracy: 0.2305 - val_loss: 2.0996 - val_accuracy: 0.4969\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.9124 - accuracy: 0.5117 - val_loss: 1.6828 - val_accuracy: 0.6469\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.4353 - accuracy: 0.6414 - val_loss: 1.2367 - val_accuracy: 0.6812\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0233 - accuracy: 0.7039 - val_loss: 0.9694 - val_accuracy: 0.7094\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.7621 - accuracy: 0.7734 - val_loss: 0.8511 - val_accuracy: 0.7094\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6583 - accuracy: 0.7930 - val_loss: 0.7940 - val_accuracy: 0.7312\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5559 - accuracy: 0.8383 - val_loss: 0.8073 - val_accuracy: 0.7312\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.8531 - val_loss: 0.7996 - val_accuracy: 0.7250\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4079 - accuracy: 0.8820 - val_loss: 0.8089 - val_accuracy: 0.7219\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8961 - val_loss: 0.8484 - val_accuracy: 0.7188\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8922 - val_loss: 0.8040 - val_accuracy: 0.7125\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8517 - accuracy: 0.7425\n",
      "Test accuracy: 74.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# Then proceed with train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Dq, \n",
    "    df['encoded_topics'], \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['encoded_topics']  # This ensures stratified splitting\n",
    ")\n",
    "\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train_flattened.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train_flattened, y_train_encoded, epochs=100, batch_size=64, \n",
    "                    validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_flattened, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9a1d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.84      0.95      0.89        40\n",
      "     Class 2       0.80      0.60      0.69        40\n",
      "     Class 3       1.00      0.75      0.86        40\n",
      "     Class 4       0.76      0.78      0.77        40\n",
      "     Class 5       0.62      0.70      0.66        40\n",
      "     Class 6       0.56      0.50      0.53        40\n",
      "     Class 7       0.75      0.68      0.71        40\n",
      "     Class 8       0.64      0.68      0.66        40\n",
      "     Class 9       0.66      0.88      0.75        40\n",
      "    Class 10       0.88      0.93      0.90        40\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.75      0.74      0.74       400\n",
      "weighted avg       0.75      0.74      0.74       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from numpy import argmax, unique\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test_flattened)  # Ensure this matches your reshaped test data variable\n",
    "\n",
    "\n",
    "predictions_int = argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "y_test_int = argmax(y_test_encoded, axis=1)\n",
    "\n",
    "\n",
    "all_classes = unique(np.concatenate((y_test_int, predictions_int)))\n",
    "\n",
    "\n",
    "target_names = [f'Class {i+1}' for i in all_classes]  \n",
    "\n",
    "\n",
    "report = classification_report(y_test_int, predictions_int, target_names=target_names)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbf445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
